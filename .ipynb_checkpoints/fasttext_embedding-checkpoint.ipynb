{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fasttext embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stvaramo embeddinge, tj. vektore za svaki query i product. Ovo radimo kako bi ih prezentirali u vektorskom prostoru. Fasttext je samo jedna od metoda kojom mozemo to raditi, mozemo isprobati i neke kao sto su word2vec, sentence2vec, TFIDF, itd. Fasttext prezentira tekst kao vektor dimenzije 300 na nacin da gleda postoji li rijec iz teksta u njegovom vokabularu. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim \n",
    "from gensim.models.wrappers import fasttext\n",
    "import fasttext.util\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#citamo vec stvoreni dataset s pretprocesiranim querijima i productima\n",
    "\n",
    "df_preprocessed = pd.read_csv(filepath_or_buffer='./Dataset/dataframes/df_preprocessed.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_preprocessed.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim \n",
    "from gensim.models.wrappers import fasttext\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#racuna fasttext vektor za svaku rijec u tekstu i racuna prosjek svih vektora\n",
    "\n",
    "def get_vector_average(text):\n",
    "  vectors = 0\n",
    "  numOfExceptableWords = 0  #ukupni broj rijeci za koje cemo izgenerirati vektore\n",
    "  for w in text:\n",
    "    try:                    #ako neka rijec ne postoji u vokabularu baca se iznimka\n",
    "      vec = ft.get_word_vector(w)\n",
    "      vectors += vec\n",
    "      numOfExceptableWords +=1\n",
    "    except:\n",
    "      continue\n",
    "  \n",
    "  vecM=vectors/numOfExceptableWords\n",
    "  listV=[]\n",
    "  for v in vecM:\n",
    "    listV.append(str(v))\n",
    "    \n",
    "  return listV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#racunaj vektore za querije i producte, ostale samo prepisi u novi dataset\n",
    "\n",
    "d= {'id': [], 'query_vector': [], 'product_vector': [], 'median_relevance': [], 'relevance_variance': []}\n",
    "df_pp_fasttext = pd.DataFrame(data=d)\n",
    "\n",
    "query_average = []\n",
    "products_average = []\n",
    "ids = []\n",
    "medians = []\n",
    "variances = []\n",
    "\n",
    " \n",
    "for i, item in df_preprocessed.iterrows():\n",
    "  ids.append(item[\"id\"])\n",
    "  medians.append(item[\"median_relevance\"])\n",
    "  variances.append(item[\"relevance_variance\"])\n",
    "  query_words = item[\"query\"].split()\n",
    "  product_words = item[\"product\"].split()\n",
    "  \n",
    "  query_average.append(get_vector_average(item[\"query\"].split()))\n",
    "  products_average.append(get_vector_average(item[\"product\"].split()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pp_fasttext['id']=ids\n",
    "df_pp_fasttext['query_vector']=query_average\n",
    "df_pp_fasttext['product_vector']=products_average\n",
    "df_pp_fasttext['median_relevance']=medians\n",
    "df_pp_fasttext['relevance_variance']=variances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_pp_fasttext[\"query_vector\"].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(df_pp_fasttext[\"product_vector\"][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_pp_fasttext.to_csv(r'./Dataset/dataframes/df_pp_fasttext.csv', encoding='utf-8', header='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = {}\n",
    "df[\"entity\"] = []\n",
    "for i, o in df_pp_fasttext.iterrows(): \n",
    "  df[\"entity\"].append({\n",
    "         \"id\": o.id,\n",
    "         \"query_vector\": o.query_vector,\n",
    "         \"product_vector\": o.product_vector,\n",
    "         \"median_relevance\": o.median_relevance,\n",
    "         \"relevance_variance\": o.relevance_variance\n",
    "  })\n",
    " \n",
    "with open('df_pp_fasttext.json', 'w') as outfile:\n",
    "  json.dump(df[\"entity\"],outfile,indent=3)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f2bf11d8767c50a74e7ca8cca20ade7bf72bdfe435dc3a1ec7a8fe848b18ee20"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
