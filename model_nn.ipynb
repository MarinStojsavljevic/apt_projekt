{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ljd46Ow12GAI"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import numpy as np\n",
        "import csv\n",
        "import json\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogQ6as_x2KMQ",
        "outputId": "e3b62238-d923-4773-85ad-b0a010c2098b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LoAdwJ9D2GAP"
      },
      "outputs": [],
      "source": [
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_word2vec_with_numbers.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_word2vec_with_numbers = pd.DataFrame(dataJSON)\n",
        "\n",
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_word2vec_without_all_tokens_with_numbers.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_word2vec_without_all_tokens_with_numbers = pd.DataFrame(dataJSON)\n",
        "\n",
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_word2vec_without_numbers_partially.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_word2vec_without_numbers_partially = pd.DataFrame(dataJSON)\n",
        "\n",
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_fasttext_with_numbers.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_fasttext_with_numbers = pd.DataFrame(dataJSON)\n",
        "\n",
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_fasttext_without_all_tokens_with_numbers.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_fasttext_without_all_tokens_with_numbers = pd.DataFrame(dataJSON)\n",
        "\n",
        "dataJSON  = []\n",
        "with open(\"/content/drive/MyDrive/APT/Datasets/df_fasttext_without_numbers_partially.json\", 'r') as f:\n",
        "  dataJSON=json.load(f)\n",
        "  df_fasttext_without_numbers_partially = pd.DataFrame(dataJSON)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df = df_word2vec_with_numbers\n",
        "#df = df_word2vec_without_all_tokens_with_numbers\n",
        "#df = df_word2vec_without_numbers_partially\n",
        "#df = df_fasttext_with_numbers\n",
        "#df = df_fasttext_without_all_tokens_with_numbers\n",
        "df = df_fasttext_without_numbers_partially"
      ],
      "metadata": {
        "id": "FcHkLnAhuyvD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dvjok_GG2GAW"
      },
      "outputs": [],
      "source": [
        "#konkateniraj vektore u jedan zajednicki\n",
        "\n",
        "df[\"allVectors\"] = df[\"query_vector\"] + df[\"product_vector\"] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Gmlih5W2GAW",
        "outputId": "aa5ee1cd-0172-4734-dd1d-c9c5c36fe92a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0    [-0.067871094, 0.122558594, -0.17480469, 0.086...\n",
            "Name: allVectors, dtype: object\n"
          ]
        }
      ],
      "source": [
        "print(df[\"allVectors\"].head(1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XYMiwqF2GAX",
        "outputId": "f1c5dea4-f22f-4e05-aa5f-c932729f0390"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "df['allVectors']=df['allVectors'].apply(lambda x : np.asarray(x,np.float))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['median_relevance'] = df['median_relevance'] /df['median_relevance'].abs().max() #sve vrijednosti izmedu 0.25 i 1.00"
      ],
      "metadata": {
        "id": "SG1nWoyQwO2m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.head(5))"
      ],
      "metadata": {
        "id": "9Kp4npY1wYW6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fae8a97e-b7f9-41dc-b34b-8d9a4204cd0f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "   id                                       query_vector  \\\n",
            "0   1  [-0.067871094, 0.122558594, -0.17480469, 0.086...   \n",
            "1   2  [-0.0040283203, 0.15348308, 0.019042969, -0.11...   \n",
            "2   4  [0.23632812, -0.040527344, -0.05078125, 0.0478...   \n",
            "3   5  [-0.13476562, 0.026855469, -0.24902344, 0.1118...   \n",
            "4   7  [-0.005859375, 0.23632812, 0.16137695, -0.0783...   \n",
            "\n",
            "                                      product_vector  median_relevance  \\\n",
            "0  [0.010758463, 0.015542602, 0.008837891, 0.0595...              0.25   \n",
            "1  [-0.027775712, 0.10037037, 0.040850554, -0.007...              1.00   \n",
            "2  [0.15576172, -0.030273438, -0.16113281, -0.006...              1.00   \n",
            "3  [0.007836914, 0.09597798, -0.07133923, 0.03092...              1.00   \n",
            "4  [-0.029772883, 0.10301524, 0.021087646, 0.0199...              0.50   \n",
            "\n",
            "   relevance_variance                                         allVectors  \n",
            "0               0.000  [-0.067871094, 0.122558594, -0.17480469, 0.086...  \n",
            "1               0.000  [-0.0040283203, 0.15348308, 0.019042969, -0.11...  \n",
            "2               0.471  [0.23632812, -0.040527344, -0.05078125, 0.0478...  \n",
            "3               0.000  [-0.13476562, 0.026855469, -0.24902344, 0.1118...  \n",
            "4               0.471  [-0.005859375, 0.23632812, 0.16137695, -0.0783...  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WLwWU9rz2GAY"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df['allVectors'], df['median_relevance'],test_size=0.4, random_state=42) \n",
        "\n",
        "X_test, X_val, y_test, y_val  = train_test_split(X_test, y_test, test_size=0.5, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pb0JVUuD2GAZ"
      },
      "outputs": [],
      "source": [
        "X_tr_ind=X_train.index.to_numpy()\n",
        "X_tst_ind=X_test.index.to_numpy()\n",
        "X_val_ind=X_val.index.to_numpy()\n",
        "\n",
        "y_train = y_train.to_numpy()\n",
        "y_test = y_test.to_numpy()\n",
        "y_val = y_val.to_numpy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vsb8pjzZ2GAa"
      },
      "outputs": [],
      "source": [
        "X_test=np.vstack(X_test)\n",
        "X_train=np.vstack(X_train)\n",
        "X_val=np.vstack(X_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Bnj4rtr2GAa",
        "outputId": "0e2e00ee-5962-4b10-e4bd-da66c9d0fe27"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6094, 600)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QccQaBf42GAb"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow.keras as K\n",
        "from tensorflow.keras.models import load_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hVxhaqMU2GAc"
      },
      "outputs": [],
      "source": [
        "network=K.Sequential([\n",
        "    K.layers.InputLayer(600),\n",
        "    K.layers.BatchNormalization(),\n",
        "    K.layers.Dropout(0.25),\n",
        "    K.layers.Dense(1000,activation='relu'),\n",
        "    K.layers.BatchNormalization(),\n",
        "    K.layers.Dropout(0.25),\n",
        "    K.layers.Dense(200,activation='relu'),\n",
        "    K.layers.BatchNormalization(),\n",
        "    K.layers.Dropout(0.25),\n",
        "    K.layers.Dense(100, activation='relu'),\n",
        "    K.layers.BatchNormalization(),\n",
        "    K.layers.Dropout(0.25),\n",
        "    K.layers.Dense(1, activation='relu')])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HjYens72GAd"
      },
      "outputs": [],
      "source": [
        "network.compile(loss=tf.keras.losses.huber, optimizer='adam', metrics=['mse']) #tf.keras.losses.SparseCategoricalCrossentropy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "network.summary()"
      ],
      "metadata": {
        "id": "OkVdbG72FzI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unBrJukC2GAe",
        "outputId": "cc29ed63-a5a8-4c73-d3cd-418b019af737"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "3/3 [==============================] - 3s 427ms/step - loss: 0.3772 - mse: 0.8749 - val_loss: 0.3722 - val_mse: 0.7444\n",
            "Epoch 2/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.3151 - mse: 0.6815 - val_loss: 0.3725 - val_mse: 0.7450\n",
            "Epoch 3/300\n",
            "3/3 [==============================] - 1s 349ms/step - loss: 0.2833 - mse: 0.5873 - val_loss: 0.3701 - val_mse: 0.7401\n",
            "Epoch 4/300\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.2679 - mse: 0.5465 - val_loss: 0.3598 - val_mse: 0.7196\n",
            "Epoch 5/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.2538 - mse: 0.5181 - val_loss: 0.3330 - val_mse: 0.6659\n",
            "Epoch 6/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.2421 - mse: 0.4904 - val_loss: 0.2903 - val_mse: 0.5807\n",
            "Epoch 7/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.2330 - mse: 0.4721 - val_loss: 0.2492 - val_mse: 0.4983\n",
            "Epoch 8/300\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.2208 - mse: 0.4438 - val_loss: 0.2233 - val_mse: 0.4466\n",
            "Epoch 9/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.2009 - mse: 0.4039 - val_loss: 0.2041 - val_mse: 0.4082\n",
            "Epoch 10/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.1931 - mse: 0.3891 - val_loss: 0.1825 - val_mse: 0.3650\n",
            "Epoch 11/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.1833 - mse: 0.3684 - val_loss: 0.1654 - val_mse: 0.3308\n",
            "Epoch 12/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.1704 - mse: 0.3422 - val_loss: 0.1484 - val_mse: 0.2968\n",
            "Epoch 13/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.1599 - mse: 0.3208 - val_loss: 0.1325 - val_mse: 0.2649\n",
            "Epoch 14/300\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.1491 - mse: 0.2988 - val_loss: 0.1206 - val_mse: 0.2411\n",
            "Epoch 15/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.1393 - mse: 0.2790 - val_loss: 0.1056 - val_mse: 0.2112\n",
            "Epoch 16/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.1315 - mse: 0.2633 - val_loss: 0.0916 - val_mse: 0.1832\n",
            "Epoch 17/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.1258 - mse: 0.2521 - val_loss: 0.0860 - val_mse: 0.1720\n",
            "Epoch 18/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.1171 - mse: 0.2345 - val_loss: 0.0808 - val_mse: 0.1617\n",
            "Epoch 19/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.1134 - mse: 0.2271 - val_loss: 0.0715 - val_mse: 0.1430\n",
            "Epoch 20/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.1055 - mse: 0.2113 - val_loss: 0.0655 - val_mse: 0.1310\n",
            "Epoch 21/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0999 - mse: 0.2001 - val_loss: 0.0608 - val_mse: 0.1217\n",
            "Epoch 22/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0949 - mse: 0.1904 - val_loss: 0.0563 - val_mse: 0.1125\n",
            "Epoch 23/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0917 - mse: 0.1834 - val_loss: 0.0504 - val_mse: 0.1007\n",
            "Epoch 24/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0882 - mse: 0.1764 - val_loss: 0.0452 - val_mse: 0.0905\n",
            "Epoch 25/300\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.0848 - mse: 0.1699 - val_loss: 0.0424 - val_mse: 0.0848\n",
            "Epoch 26/300\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.0822 - mse: 0.1646 - val_loss: 0.0412 - val_mse: 0.0823\n",
            "Epoch 27/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0785 - mse: 0.1579 - val_loss: 0.0402 - val_mse: 0.0804\n",
            "Epoch 28/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0759 - mse: 0.1519 - val_loss: 0.0395 - val_mse: 0.0789\n",
            "Epoch 29/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0733 - mse: 0.1467 - val_loss: 0.0384 - val_mse: 0.0768\n",
            "Epoch 30/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0711 - mse: 0.1422 - val_loss: 0.0368 - val_mse: 0.0736\n",
            "Epoch 31/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0685 - mse: 0.1369 - val_loss: 0.0354 - val_mse: 0.0707\n",
            "Epoch 32/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0690 - mse: 0.1382 - val_loss: 0.0343 - val_mse: 0.0685\n",
            "Epoch 33/300\n",
            "3/3 [==============================] - 1s 313ms/step - loss: 0.0659 - mse: 0.1318 - val_loss: 0.0335 - val_mse: 0.0669\n",
            "Epoch 34/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0645 - mse: 0.1290 - val_loss: 0.0330 - val_mse: 0.0660\n",
            "Epoch 35/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0616 - mse: 0.1233 - val_loss: 0.0326 - val_mse: 0.0652\n",
            "Epoch 36/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0597 - mse: 0.1194 - val_loss: 0.0321 - val_mse: 0.0643\n",
            "Epoch 37/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0606 - mse: 0.1221 - val_loss: 0.0319 - val_mse: 0.0638\n",
            "Epoch 38/300\n",
            "3/3 [==============================] - 1s 353ms/step - loss: 0.0584 - mse: 0.1170 - val_loss: 0.0317 - val_mse: 0.0635\n",
            "Epoch 39/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0567 - mse: 0.1135 - val_loss: 0.0318 - val_mse: 0.0635\n",
            "Epoch 40/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0547 - mse: 0.1096 - val_loss: 0.0319 - val_mse: 0.0638\n",
            "Epoch 41/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0547 - mse: 0.1098 - val_loss: 0.0319 - val_mse: 0.0639\n",
            "Epoch 42/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0531 - mse: 0.1062 - val_loss: 0.0321 - val_mse: 0.0641\n",
            "Epoch 43/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0510 - mse: 0.1020 - val_loss: 0.0323 - val_mse: 0.0646\n",
            "Epoch 44/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0496 - mse: 0.0993 - val_loss: 0.0324 - val_mse: 0.0648\n",
            "Epoch 45/300\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.0483 - mse: 0.0966 - val_loss: 0.0324 - val_mse: 0.0649\n",
            "Epoch 46/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0477 - mse: 0.0957 - val_loss: 0.0325 - val_mse: 0.0650\n",
            "Epoch 47/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0472 - mse: 0.0947 - val_loss: 0.0329 - val_mse: 0.0659\n",
            "Epoch 48/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0446 - mse: 0.0893 - val_loss: 0.0335 - val_mse: 0.0669\n",
            "Epoch 49/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0441 - mse: 0.0889 - val_loss: 0.0337 - val_mse: 0.0674\n",
            "Epoch 50/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0421 - mse: 0.0843 - val_loss: 0.0336 - val_mse: 0.0671\n",
            "Epoch 51/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0409 - mse: 0.0818 - val_loss: 0.0329 - val_mse: 0.0657\n",
            "Epoch 52/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0409 - mse: 0.0820 - val_loss: 0.0325 - val_mse: 0.0649\n",
            "Epoch 53/300\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 0.0394 - mse: 0.0788 - val_loss: 0.0325 - val_mse: 0.0651\n",
            "Epoch 54/300\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.0395 - mse: 0.0792 - val_loss: 0.0329 - val_mse: 0.0657\n",
            "Epoch 55/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0383 - mse: 0.0767 - val_loss: 0.0330 - val_mse: 0.0659\n",
            "Epoch 56/300\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.0378 - mse: 0.0756 - val_loss: 0.0327 - val_mse: 0.0655\n",
            "Epoch 57/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0376 - mse: 0.0751 - val_loss: 0.0323 - val_mse: 0.0646\n",
            "Epoch 58/300\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.0365 - mse: 0.0732 - val_loss: 0.0320 - val_mse: 0.0639\n",
            "Epoch 59/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0364 - mse: 0.0731 - val_loss: 0.0319 - val_mse: 0.0638\n",
            "Epoch 60/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0355 - mse: 0.0710 - val_loss: 0.0321 - val_mse: 0.0643\n",
            "Epoch 61/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0343 - mse: 0.0686 - val_loss: 0.0324 - val_mse: 0.0647\n",
            "Epoch 62/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0335 - mse: 0.0669 - val_loss: 0.0321 - val_mse: 0.0643\n",
            "Epoch 63/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0331 - mse: 0.0662 - val_loss: 0.0316 - val_mse: 0.0631\n",
            "Epoch 64/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0339 - mse: 0.0677 - val_loss: 0.0312 - val_mse: 0.0624\n",
            "Epoch 65/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0341 - mse: 0.0684 - val_loss: 0.0310 - val_mse: 0.0619\n",
            "Epoch 66/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0322 - mse: 0.0644 - val_loss: 0.0308 - val_mse: 0.0617\n",
            "Epoch 67/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0333 - mse: 0.0666 - val_loss: 0.0308 - val_mse: 0.0616\n",
            "Epoch 68/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0316 - mse: 0.0633 - val_loss: 0.0308 - val_mse: 0.0617\n",
            "Epoch 69/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0314 - mse: 0.0628 - val_loss: 0.0307 - val_mse: 0.0614\n",
            "Epoch 70/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0309 - mse: 0.0618 - val_loss: 0.0305 - val_mse: 0.0611\n",
            "Epoch 71/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0310 - mse: 0.0619 - val_loss: 0.0305 - val_mse: 0.0610\n",
            "Epoch 72/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0303 - mse: 0.0606 - val_loss: 0.0305 - val_mse: 0.0609\n",
            "Epoch 73/300\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.0305 - mse: 0.0611 - val_loss: 0.0303 - val_mse: 0.0606\n",
            "Epoch 74/300\n",
            "3/3 [==============================] - 1s 351ms/step - loss: 0.0309 - mse: 0.0620 - val_loss: 0.0302 - val_mse: 0.0604\n",
            "Epoch 75/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0301 - mse: 0.0601 - val_loss: 0.0301 - val_mse: 0.0603\n",
            "Epoch 76/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0295 - mse: 0.0591 - val_loss: 0.0301 - val_mse: 0.0601\n",
            "Epoch 77/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0293 - mse: 0.0586 - val_loss: 0.0299 - val_mse: 0.0599\n",
            "Epoch 78/300\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 0.0293 - mse: 0.0586 - val_loss: 0.0299 - val_mse: 0.0598\n",
            "Epoch 79/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0291 - mse: 0.0582 - val_loss: 0.0298 - val_mse: 0.0596\n",
            "Epoch 80/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0286 - mse: 0.0572 - val_loss: 0.0298 - val_mse: 0.0595\n",
            "Epoch 81/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0289 - mse: 0.0577 - val_loss: 0.0298 - val_mse: 0.0596\n",
            "Epoch 82/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0285 - mse: 0.0571 - val_loss: 0.0297 - val_mse: 0.0593\n",
            "Epoch 83/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0276 - mse: 0.0551 - val_loss: 0.0296 - val_mse: 0.0591\n",
            "Epoch 84/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0282 - mse: 0.0564 - val_loss: 0.0296 - val_mse: 0.0592\n",
            "Epoch 85/300\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.0283 - mse: 0.0565 - val_loss: 0.0297 - val_mse: 0.0594\n",
            "Epoch 86/300\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.0272 - mse: 0.0543 - val_loss: 0.0296 - val_mse: 0.0591\n",
            "Epoch 87/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0282 - mse: 0.0565 - val_loss: 0.0295 - val_mse: 0.0589\n",
            "Epoch 88/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0274 - mse: 0.0548 - val_loss: 0.0293 - val_mse: 0.0586\n",
            "Epoch 89/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0280 - mse: 0.0560 - val_loss: 0.0292 - val_mse: 0.0584\n",
            "Epoch 90/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0268 - mse: 0.0536 - val_loss: 0.0291 - val_mse: 0.0581\n",
            "Epoch 91/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0269 - mse: 0.0539 - val_loss: 0.0290 - val_mse: 0.0579\n",
            "Epoch 92/300\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.0264 - mse: 0.0529 - val_loss: 0.0291 - val_mse: 0.0582\n",
            "Epoch 93/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0266 - mse: 0.0532 - val_loss: 0.0292 - val_mse: 0.0584\n",
            "Epoch 94/300\n",
            "3/3 [==============================] - 1s 349ms/step - loss: 0.0260 - mse: 0.0519 - val_loss: 0.0290 - val_mse: 0.0580\n",
            "Epoch 95/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0260 - mse: 0.0520 - val_loss: 0.0288 - val_mse: 0.0576\n",
            "Epoch 96/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0263 - mse: 0.0528 - val_loss: 0.0286 - val_mse: 0.0572\n",
            "Epoch 97/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0258 - mse: 0.0516 - val_loss: 0.0285 - val_mse: 0.0571\n",
            "Epoch 98/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0255 - mse: 0.0510 - val_loss: 0.0285 - val_mse: 0.0569\n",
            "Epoch 99/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0252 - mse: 0.0504 - val_loss: 0.0284 - val_mse: 0.0568\n",
            "Epoch 100/300\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.0256 - mse: 0.0512 - val_loss: 0.0282 - val_mse: 0.0565\n",
            "Epoch 101/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0256 - mse: 0.0512 - val_loss: 0.0281 - val_mse: 0.0563\n",
            "Epoch 102/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0255 - mse: 0.0510 - val_loss: 0.0281 - val_mse: 0.0562\n",
            "Epoch 103/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0250 - mse: 0.0501 - val_loss: 0.0281 - val_mse: 0.0561\n",
            "Epoch 104/300\n",
            "3/3 [==============================] - 1s 533ms/step - loss: 0.0254 - mse: 0.0508 - val_loss: 0.0280 - val_mse: 0.0560\n",
            "Epoch 105/300\n",
            "3/3 [==============================] - 2s 605ms/step - loss: 0.0257 - mse: 0.0515 - val_loss: 0.0279 - val_mse: 0.0558\n",
            "Epoch 106/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0248 - mse: 0.0495 - val_loss: 0.0277 - val_mse: 0.0555\n",
            "Epoch 107/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0245 - mse: 0.0490 - val_loss: 0.0276 - val_mse: 0.0552\n",
            "Epoch 108/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0248 - mse: 0.0497 - val_loss: 0.0275 - val_mse: 0.0550\n",
            "Epoch 109/300\n",
            "3/3 [==============================] - 1s 316ms/step - loss: 0.0242 - mse: 0.0484 - val_loss: 0.0274 - val_mse: 0.0548\n",
            "Epoch 110/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0245 - mse: 0.0490 - val_loss: 0.0273 - val_mse: 0.0547\n",
            "Epoch 111/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0243 - mse: 0.0485 - val_loss: 0.0273 - val_mse: 0.0547\n",
            "Epoch 112/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0240 - mse: 0.0480 - val_loss: 0.0272 - val_mse: 0.0544\n",
            "Epoch 113/300\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.0245 - mse: 0.0489 - val_loss: 0.0271 - val_mse: 0.0542\n",
            "Epoch 114/300\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.0236 - mse: 0.0473 - val_loss: 0.0269 - val_mse: 0.0539\n",
            "Epoch 115/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0244 - mse: 0.0488 - val_loss: 0.0267 - val_mse: 0.0534\n",
            "Epoch 116/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0235 - mse: 0.0470 - val_loss: 0.0265 - val_mse: 0.0530\n",
            "Epoch 117/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0244 - mse: 0.0488 - val_loss: 0.0264 - val_mse: 0.0529\n",
            "Epoch 118/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0236 - mse: 0.0471 - val_loss: 0.0262 - val_mse: 0.0525\n",
            "Epoch 119/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0232 - mse: 0.0464 - val_loss: 0.0262 - val_mse: 0.0523\n",
            "Epoch 120/300\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.0237 - mse: 0.0474 - val_loss: 0.0261 - val_mse: 0.0523\n",
            "Epoch 121/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0232 - mse: 0.0463 - val_loss: 0.0260 - val_mse: 0.0521\n",
            "Epoch 122/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0235 - mse: 0.0470 - val_loss: 0.0259 - val_mse: 0.0517\n",
            "Epoch 123/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0228 - mse: 0.0456 - val_loss: 0.0257 - val_mse: 0.0513\n",
            "Epoch 124/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0226 - mse: 0.0453 - val_loss: 0.0255 - val_mse: 0.0510\n",
            "Epoch 125/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0227 - mse: 0.0455 - val_loss: 0.0254 - val_mse: 0.0508\n",
            "Epoch 126/300\n",
            "3/3 [==============================] - 1s 346ms/step - loss: 0.0227 - mse: 0.0454 - val_loss: 0.0253 - val_mse: 0.0507\n",
            "Epoch 127/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0221 - mse: 0.0441 - val_loss: 0.0253 - val_mse: 0.0507\n",
            "Epoch 128/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0228 - mse: 0.0456 - val_loss: 0.0253 - val_mse: 0.0506\n",
            "Epoch 129/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0221 - mse: 0.0441 - val_loss: 0.0252 - val_mse: 0.0504\n",
            "Epoch 130/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0224 - mse: 0.0448 - val_loss: 0.0250 - val_mse: 0.0500\n",
            "Epoch 131/300\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.0223 - mse: 0.0447 - val_loss: 0.0248 - val_mse: 0.0496\n",
            "Epoch 132/300\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.0227 - mse: 0.0454 - val_loss: 0.0248 - val_mse: 0.0496\n",
            "Epoch 133/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0222 - mse: 0.0445 - val_loss: 0.0248 - val_mse: 0.0496\n",
            "Epoch 134/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0221 - mse: 0.0442 - val_loss: 0.0247 - val_mse: 0.0494\n",
            "Epoch 135/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0223 - mse: 0.0447 - val_loss: 0.0246 - val_mse: 0.0493\n",
            "Epoch 136/300\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.0220 - mse: 0.0439 - val_loss: 0.0247 - val_mse: 0.0495\n",
            "Epoch 137/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0219 - mse: 0.0438 - val_loss: 0.0247 - val_mse: 0.0493\n",
            "Epoch 138/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0213 - mse: 0.0426 - val_loss: 0.0245 - val_mse: 0.0490\n",
            "Epoch 139/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0210 - mse: 0.0420 - val_loss: 0.0243 - val_mse: 0.0487\n",
            "Epoch 140/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0206 - mse: 0.0411 - val_loss: 0.0242 - val_mse: 0.0485\n",
            "Epoch 141/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0211 - mse: 0.0423 - val_loss: 0.0242 - val_mse: 0.0484\n",
            "Epoch 142/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0220 - mse: 0.0469 - val_loss: 0.0243 - val_mse: 0.0485\n",
            "Epoch 143/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0209 - mse: 0.0418 - val_loss: 0.0240 - val_mse: 0.0481\n",
            "Epoch 144/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0213 - mse: 0.0429 - val_loss: 0.0238 - val_mse: 0.0475\n",
            "Epoch 145/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0211 - mse: 0.0423 - val_loss: 0.0237 - val_mse: 0.0473\n",
            "Epoch 146/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0211 - mse: 0.0423 - val_loss: 0.0236 - val_mse: 0.0472\n",
            "Epoch 147/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0201 - mse: 0.0402 - val_loss: 0.0236 - val_mse: 0.0472\n",
            "Epoch 148/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0204 - mse: 0.0408 - val_loss: 0.0235 - val_mse: 0.0471\n",
            "Epoch 149/300\n",
            "3/3 [==============================] - 1s 348ms/step - loss: 0.0201 - mse: 0.0403 - val_loss: 0.0233 - val_mse: 0.0466\n",
            "Epoch 150/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0204 - mse: 0.0409 - val_loss: 0.0231 - val_mse: 0.0461\n",
            "Epoch 151/300\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.0208 - mse: 0.0420 - val_loss: 0.0230 - val_mse: 0.0461\n",
            "Epoch 152/300\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.0199 - mse: 0.0399 - val_loss: 0.0230 - val_mse: 0.0460\n",
            "Epoch 153/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0201 - mse: 0.0402 - val_loss: 0.0229 - val_mse: 0.0458\n",
            "Epoch 154/300\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.0199 - mse: 0.0399 - val_loss: 0.0227 - val_mse: 0.0454\n",
            "Epoch 155/300\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 0.0191 - mse: 0.0381 - val_loss: 0.0226 - val_mse: 0.0452\n",
            "Epoch 156/300\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.0199 - mse: 0.0404 - val_loss: 0.0227 - val_mse: 0.0454\n",
            "Epoch 157/300\n",
            "3/3 [==============================] - 1s 347ms/step - loss: 0.0195 - mse: 0.0405 - val_loss: 0.0229 - val_mse: 0.0459\n",
            "Epoch 158/300\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.0195 - mse: 0.0390 - val_loss: 0.0230 - val_mse: 0.0461\n",
            "Epoch 159/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0192 - mse: 0.0383 - val_loss: 0.0229 - val_mse: 0.0457\n",
            "Epoch 160/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0183 - mse: 0.0366 - val_loss: 0.0225 - val_mse: 0.0450\n",
            "Epoch 161/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0190 - mse: 0.0382 - val_loss: 0.0222 - val_mse: 0.0445\n",
            "Epoch 162/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0187 - mse: 0.0374 - val_loss: 0.0221 - val_mse: 0.0442\n",
            "Epoch 163/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0187 - mse: 0.0374 - val_loss: 0.0220 - val_mse: 0.0440\n",
            "Epoch 164/300\n",
            "3/3 [==============================] - 1s 319ms/step - loss: 0.0191 - mse: 0.0382 - val_loss: 0.0221 - val_mse: 0.0442\n",
            "Epoch 165/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0181 - mse: 0.0363 - val_loss: 0.0221 - val_mse: 0.0443\n",
            "Epoch 166/300\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 0.0195 - mse: 0.0395 - val_loss: 0.0221 - val_mse: 0.0441\n",
            "Epoch 167/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0181 - mse: 0.0363 - val_loss: 0.0222 - val_mse: 0.0444\n",
            "Epoch 168/300\n",
            "3/3 [==============================] - 1s 336ms/step - loss: 0.0183 - mse: 0.0365 - val_loss: 0.0221 - val_mse: 0.0443\n",
            "Epoch 169/300\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 0.0180 - mse: 0.0359 - val_loss: 0.0219 - val_mse: 0.0439\n",
            "Epoch 170/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0181 - mse: 0.0361 - val_loss: 0.0219 - val_mse: 0.0438\n",
            "Epoch 171/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0183 - mse: 0.0366 - val_loss: 0.0218 - val_mse: 0.0436\n",
            "Epoch 172/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0176 - mse: 0.0352 - val_loss: 0.0219 - val_mse: 0.0438\n",
            "Epoch 173/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0175 - mse: 0.0351 - val_loss: 0.0221 - val_mse: 0.0443\n",
            "Epoch 174/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0173 - mse: 0.0346 - val_loss: 0.0221 - val_mse: 0.0442\n",
            "Epoch 175/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0176 - mse: 0.0353 - val_loss: 0.0219 - val_mse: 0.0438\n",
            "Epoch 176/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0168 - mse: 0.0337 - val_loss: 0.0219 - val_mse: 0.0438\n",
            "Epoch 177/300\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.0168 - mse: 0.0336 - val_loss: 0.0218 - val_mse: 0.0437\n",
            "Epoch 178/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0166 - mse: 0.0332 - val_loss: 0.0217 - val_mse: 0.0433\n",
            "Epoch 179/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0169 - mse: 0.0339 - val_loss: 0.0218 - val_mse: 0.0435\n",
            "Epoch 180/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0165 - mse: 0.0329 - val_loss: 0.0217 - val_mse: 0.0434\n",
            "Epoch 181/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0166 - mse: 0.0332 - val_loss: 0.0215 - val_mse: 0.0430\n",
            "Epoch 182/300\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.0167 - mse: 0.0334 - val_loss: 0.0213 - val_mse: 0.0427\n",
            "Epoch 183/300\n",
            "3/3 [==============================] - 1s 339ms/step - loss: 0.0163 - mse: 0.0326 - val_loss: 0.0213 - val_mse: 0.0426\n",
            "Epoch 184/300\n",
            "3/3 [==============================] - 1s 407ms/step - loss: 0.0164 - mse: 0.0328 - val_loss: 0.0212 - val_mse: 0.0424\n",
            "Epoch 185/300\n",
            "3/3 [==============================] - 2s 568ms/step - loss: 0.0162 - mse: 0.0324 - val_loss: 0.0213 - val_mse: 0.0425\n",
            "Epoch 186/300\n",
            "3/3 [==============================] - 2s 536ms/step - loss: 0.0160 - mse: 0.0320 - val_loss: 0.0214 - val_mse: 0.0428\n",
            "Epoch 187/300\n",
            "3/3 [==============================] - 1s 382ms/step - loss: 0.0164 - mse: 0.0328 - val_loss: 0.0215 - val_mse: 0.0431\n",
            "Epoch 188/300\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.0159 - mse: 0.0318 - val_loss: 0.0214 - val_mse: 0.0428\n",
            "Epoch 189/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0171 - mse: 0.0385 - val_loss: 0.0214 - val_mse: 0.0427\n",
            "Epoch 190/300\n",
            "3/3 [==============================] - 1s 344ms/step - loss: 0.0160 - mse: 0.0320 - val_loss: 0.0213 - val_mse: 0.0425\n",
            "Epoch 191/300\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 0.0158 - mse: 0.0316 - val_loss: 0.0212 - val_mse: 0.0425\n",
            "Epoch 192/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0161 - mse: 0.0321 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 193/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0172 - mse: 0.0344 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 194/300\n",
            "3/3 [==============================] - 1s 338ms/step - loss: 0.0155 - mse: 0.0311 - val_loss: 0.0207 - val_mse: 0.0414\n",
            "Epoch 195/300\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.0160 - mse: 0.0320 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 196/300\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 0.0153 - mse: 0.0306 - val_loss: 0.0208 - val_mse: 0.0415\n",
            "Epoch 197/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0156 - mse: 0.0313 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 198/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0156 - mse: 0.0312 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 199/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0151 - mse: 0.0302 - val_loss: 0.0210 - val_mse: 0.0419\n",
            "Epoch 200/300\n",
            "3/3 [==============================] - 1s 341ms/step - loss: 0.0152 - mse: 0.0305 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 201/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0154 - mse: 0.0310 - val_loss: 0.0211 - val_mse: 0.0421\n",
            "Epoch 202/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0152 - mse: 0.0305 - val_loss: 0.0209 - val_mse: 0.0419\n",
            "Epoch 203/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0152 - mse: 0.0304 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 204/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0151 - mse: 0.0303 - val_loss: 0.0208 - val_mse: 0.0417\n",
            "Epoch 205/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0151 - mse: 0.0302 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 206/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0147 - mse: 0.0294 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 207/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0146 - mse: 0.0292 - val_loss: 0.0213 - val_mse: 0.0426\n",
            "Epoch 208/300\n",
            "3/3 [==============================] - 1s 360ms/step - loss: 0.0149 - mse: 0.0298 - val_loss: 0.0212 - val_mse: 0.0424\n",
            "Epoch 209/300\n",
            "3/3 [==============================] - 1s 358ms/step - loss: 0.0151 - mse: 0.0303 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 210/300\n",
            "3/3 [==============================] - 1s 361ms/step - loss: 0.0148 - mse: 0.0295 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 211/300\n",
            "3/3 [==============================] - 1s 342ms/step - loss: 0.0148 - mse: 0.0296 - val_loss: 0.0210 - val_mse: 0.0421\n",
            "Epoch 212/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0148 - mse: 0.0296 - val_loss: 0.0212 - val_mse: 0.0423\n",
            "Epoch 213/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0146 - mse: 0.0293 - val_loss: 0.0214 - val_mse: 0.0429\n",
            "Epoch 214/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0147 - mse: 0.0294 - val_loss: 0.0215 - val_mse: 0.0430\n",
            "Epoch 215/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0146 - mse: 0.0293 - val_loss: 0.0212 - val_mse: 0.0424\n",
            "Epoch 216/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0147 - mse: 0.0295 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 217/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0145 - mse: 0.0289 - val_loss: 0.0207 - val_mse: 0.0414\n",
            "Epoch 218/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0144 - mse: 0.0288 - val_loss: 0.0208 - val_mse: 0.0415\n",
            "Epoch 219/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0146 - mse: 0.0292 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 220/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0140 - mse: 0.0280 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 221/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0148 - mse: 0.0295 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 222/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0140 - mse: 0.0279 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 223/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0135 - mse: 0.0270 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 224/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0143 - mse: 0.0285 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 225/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0138 - mse: 0.0276 - val_loss: 0.0207 - val_mse: 0.0414\n",
            "Epoch 226/300\n",
            "3/3 [==============================] - 1s 354ms/step - loss: 0.0137 - mse: 0.0274 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 227/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0140 - mse: 0.0280 - val_loss: 0.0207 - val_mse: 0.0415\n",
            "Epoch 228/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0139 - mse: 0.0278 - val_loss: 0.0208 - val_mse: 0.0417\n",
            "Epoch 229/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0139 - mse: 0.0278 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 230/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0137 - mse: 0.0273 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 231/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0137 - mse: 0.0274 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 232/300\n",
            "3/3 [==============================] - 1s 338ms/step - loss: 0.0134 - mse: 0.0267 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 233/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0137 - mse: 0.0273 - val_loss: 0.0208 - val_mse: 0.0417\n",
            "Epoch 234/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0141 - mse: 0.0287 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 235/300\n",
            "3/3 [==============================] - 1s 318ms/step - loss: 0.0138 - mse: 0.0276 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 236/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0134 - mse: 0.0267 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 237/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0135 - mse: 0.0271 - val_loss: 0.0208 - val_mse: 0.0415\n",
            "Epoch 238/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0135 - mse: 0.0270 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 239/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0137 - mse: 0.0274 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 240/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0134 - mse: 0.0267 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 241/300\n",
            "3/3 [==============================] - 1s 357ms/step - loss: 0.0134 - mse: 0.0269 - val_loss: 0.0211 - val_mse: 0.0423\n",
            "Epoch 242/300\n",
            "3/3 [==============================] - 1s 354ms/step - loss: 0.0133 - mse: 0.0266 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 243/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0133 - mse: 0.0266 - val_loss: 0.0206 - val_mse: 0.0413\n",
            "Epoch 244/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0131 - mse: 0.0262 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 245/300\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.0132 - mse: 0.0264 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 246/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0132 - mse: 0.0264 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 247/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0130 - mse: 0.0260 - val_loss: 0.0210 - val_mse: 0.0419\n",
            "Epoch 248/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0132 - mse: 0.0265 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 249/300\n",
            "3/3 [==============================] - 1s 321ms/step - loss: 0.0132 - mse: 0.0264 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 250/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0131 - mse: 0.0262 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 251/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0129 - mse: 0.0257 - val_loss: 0.0206 - val_mse: 0.0412\n",
            "Epoch 252/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0130 - mse: 0.0260 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 253/300\n",
            "3/3 [==============================] - 1s 350ms/step - loss: 0.0127 - mse: 0.0253 - val_loss: 0.0211 - val_mse: 0.0421\n",
            "Epoch 254/300\n",
            "3/3 [==============================] - 1s 351ms/step - loss: 0.0130 - mse: 0.0259 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 255/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0131 - mse: 0.0262 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 256/300\n",
            "3/3 [==============================] - 1s 343ms/step - loss: 0.0129 - mse: 0.0259 - val_loss: 0.0206 - val_mse: 0.0413\n",
            "Epoch 257/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0128 - mse: 0.0255 - val_loss: 0.0206 - val_mse: 0.0413\n",
            "Epoch 258/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0123 - mse: 0.0247 - val_loss: 0.0209 - val_mse: 0.0419\n",
            "Epoch 259/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0130 - mse: 0.0260 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 260/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0128 - mse: 0.0256 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 261/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0127 - mse: 0.0253 - val_loss: 0.0207 - val_mse: 0.0414\n",
            "Epoch 262/300\n",
            "3/3 [==============================] - 1s 356ms/step - loss: 0.0126 - mse: 0.0252 - val_loss: 0.0206 - val_mse: 0.0413\n",
            "Epoch 263/300\n",
            "3/3 [==============================] - 1s 359ms/step - loss: 0.0128 - mse: 0.0256 - val_loss: 0.0207 - val_mse: 0.0413\n",
            "Epoch 264/300\n",
            "3/3 [==============================] - 1s 337ms/step - loss: 0.0128 - mse: 0.0256 - val_loss: 0.0206 - val_mse: 0.0413\n",
            "Epoch 265/300\n",
            "3/3 [==============================] - 1s 329ms/step - loss: 0.0124 - mse: 0.0249 - val_loss: 0.0205 - val_mse: 0.0410\n",
            "Epoch 266/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0129 - mse: 0.0258 - val_loss: 0.0207 - val_mse: 0.0413\n",
            "Epoch 267/300\n",
            "3/3 [==============================] - 1s 320ms/step - loss: 0.0127 - mse: 0.0253 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 268/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0144 - mse: 0.0288 - val_loss: 0.0205 - val_mse: 0.0410\n",
            "Epoch 269/300\n",
            "3/3 [==============================] - 1s 324ms/step - loss: 0.0127 - mse: 0.0254 - val_loss: 0.0202 - val_mse: 0.0404\n",
            "Epoch 270/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0130 - mse: 0.0270 - val_loss: 0.0204 - val_mse: 0.0407\n",
            "Epoch 271/300\n",
            "3/3 [==============================] - 1s 345ms/step - loss: 0.0123 - mse: 0.0246 - val_loss: 0.0206 - val_mse: 0.0411\n",
            "Epoch 272/300\n",
            "3/3 [==============================] - 1s 362ms/step - loss: 0.0125 - mse: 0.0252 - val_loss: 0.0207 - val_mse: 0.0414\n",
            "Epoch 273/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0130 - mse: 0.0295 - val_loss: 0.0208 - val_mse: 0.0415\n",
            "Epoch 274/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0123 - mse: 0.0247 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 275/300\n",
            "3/3 [==============================] - 1s 340ms/step - loss: 0.0125 - mse: 0.0253 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 276/300\n",
            "3/3 [==============================] - 1s 335ms/step - loss: 0.0123 - mse: 0.0246 - val_loss: 0.0210 - val_mse: 0.0420\n",
            "Epoch 277/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0120 - mse: 0.0240 - val_loss: 0.0208 - val_mse: 0.0417\n",
            "Epoch 278/300\n",
            "3/3 [==============================] - 1s 365ms/step - loss: 0.0127 - mse: 0.0254 - val_loss: 0.0207 - val_mse: 0.0415\n",
            "Epoch 279/300\n",
            "3/3 [==============================] - 1s 323ms/step - loss: 0.0120 - mse: 0.0240 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 280/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0118 - mse: 0.0236 - val_loss: 0.0210 - val_mse: 0.0419\n",
            "Epoch 281/300\n",
            "3/3 [==============================] - 1s 334ms/step - loss: 0.0117 - mse: 0.0235 - val_loss: 0.0211 - val_mse: 0.0422\n",
            "Epoch 282/300\n",
            "3/3 [==============================] - 1s 326ms/step - loss: 0.0123 - mse: 0.0245 - val_loss: 0.0211 - val_mse: 0.0421\n",
            "Epoch 283/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0120 - mse: 0.0240 - val_loss: 0.0208 - val_mse: 0.0416\n",
            "Epoch 284/300\n",
            "3/3 [==============================] - 1s 322ms/step - loss: 0.0120 - mse: 0.0240 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 285/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0117 - mse: 0.0234 - val_loss: 0.0210 - val_mse: 0.0419\n",
            "Epoch 286/300\n",
            "3/3 [==============================] - 1s 325ms/step - loss: 0.0122 - mse: 0.0245 - val_loss: 0.0209 - val_mse: 0.0417\n",
            "Epoch 287/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0119 - mse: 0.0238 - val_loss: 0.0207 - val_mse: 0.0415\n",
            "Epoch 288/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0117 - mse: 0.0234 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 289/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0117 - mse: 0.0235 - val_loss: 0.0213 - val_mse: 0.0426\n",
            "Epoch 290/300\n",
            "3/3 [==============================] - 1s 367ms/step - loss: 0.0122 - mse: 0.0245 - val_loss: 0.0216 - val_mse: 0.0432\n",
            "Epoch 291/300\n",
            "3/3 [==============================] - 1s 330ms/step - loss: 0.0125 - mse: 0.0250 - val_loss: 0.0215 - val_mse: 0.0430\n",
            "Epoch 292/300\n",
            "3/3 [==============================] - 1s 351ms/step - loss: 0.0117 - mse: 0.0234 - val_loss: 0.0211 - val_mse: 0.0423\n",
            "Epoch 293/300\n",
            "3/3 [==============================] - 1s 331ms/step - loss: 0.0117 - mse: 0.0235 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 294/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0116 - mse: 0.0233 - val_loss: 0.0209 - val_mse: 0.0419\n",
            "Epoch 295/300\n",
            "3/3 [==============================] - 1s 332ms/step - loss: 0.0122 - mse: 0.0243 - val_loss: 0.0209 - val_mse: 0.0418\n",
            "Epoch 296/300\n",
            "3/3 [==============================] - 1s 333ms/step - loss: 0.0113 - mse: 0.0226 - val_loss: 0.0211 - val_mse: 0.0421\n",
            "Epoch 297/300\n",
            "3/3 [==============================] - 1s 352ms/step - loss: 0.0116 - mse: 0.0231 - val_loss: 0.0211 - val_mse: 0.0423\n",
            "Epoch 298/300\n",
            "3/3 [==============================] - 1s 328ms/step - loss: 0.0117 - mse: 0.0234 - val_loss: 0.0212 - val_mse: 0.0424\n",
            "Epoch 299/300\n",
            "3/3 [==============================] - 1s 327ms/step - loss: 0.0116 - mse: 0.0231 - val_loss: 0.0212 - val_mse: 0.0424\n",
            "Epoch 300/300\n",
            "3/3 [==============================] - 1s 317ms/step - loss: 0.0117 - mse: 0.0235 - val_loss: 0.0208 - val_mse: 0.0416\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fabbbc4ced0>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ],
      "source": [
        "network.fit(X_train,y_train,epochs=300,batch_size=2048, validation_data=(X_val,y_val))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aEov_RKs2GAf",
        "outputId": "cdaf8b12-84ca-4263-ab82-c7fdcfbd73b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 0s 4ms/step - loss: 0.0213 - mse: 0.0427\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021329661831259727, 0.042659323662519455]"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ],
      "source": [
        "network.evaluate(X_test,y_test)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = network.predict(X_test)"
      ],
      "metadata": {
        "id": "xZ4j0-Sz1oQf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.array([i*4 for i in preds])\n",
        "y_test = np.array([int(i*4) for i in y_test])"
      ],
      "metadata": {
        "id": "UBRks0HVyQ5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGu0vuCu4XEj",
        "outputId": "36825a3a-1ec5-449b-c4cc-f39b0c6dfac2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 2 3 4 1 2 4 3 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds[:20])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py5tOc9z4T4W",
        "outputId": "92eac1af-3337-4d53-8714-56540c99178d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.4869978]\n",
            " [3.6089354]\n",
            " [2.6799746]\n",
            " [1.9972954]\n",
            " [3.7932177]\n",
            " [1.4518068]\n",
            " [3.9775317]\n",
            " [3.9394073]\n",
            " [3.4723468]\n",
            " [4.0506706]\n",
            " [3.8253536]\n",
            " [3.47089  ]\n",
            " [3.763318 ]\n",
            " [3.3020566]\n",
            " [2.916606 ]\n",
            " [3.1425915]\n",
            " [3.8987842]\n",
            " [1.4672872]\n",
            " [4.0734124]\n",
            " [3.1484275]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(real, pred):\n",
        "  pred=[round(x[0]) for x in pred]\n",
        "  pred=[1 if x<1 else x for x in pred]\n",
        "  pred=[4 if x>4 else x for x in pred]\n",
        "  print(np.array(pred[:50]))\n",
        "  s=np.sum(pred == real)\n",
        "  return s/len(pred)"
      ],
      "metadata": {
        "id": "s3pev9zWWzJj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(accuracy(y_test, preds))\n",
        "\n",
        "print(y_test[:50])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1t5NWw_3JLf",
        "outputId": "e7c8ec7e-8811-4304-c26f-2b1b586578c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3 4 3 2 4 1 4 4 3 4 4 3 4 3 3 3 4 1 4 3 2 4 4 4 3 4 2 3 4 4 4 3 3 4 4 4 4\n",
            " 4 4 3 4 4 3 3 4 2 3 4 3 2]\n",
            "0.6171259842519685\n",
            "[3 4 2 3 4 1 2 4 3 4 4 4 4 2 4 4 4 1 4 4 2 4 4 4 2 3 1 4 3 2 4 3 2 4 4 4 4\n",
            " 4 4 1 3 4 2 3 4 3 2 4 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#network.save('/content/drive/MyDrive/APT/Models/word2vec_with_numbers') \n",
        "#network.save('/content/drive/MyDrive/APT/Models/word2vec_without_all_tokens_with_numbers') \n",
        "#network.save('/content/drive/MyDrive/APT/Models/word2vec_without_numbers_partially') \n",
        "#network.save('/content/drive/MyDrive/APT/Models/fasttext_with_numbers') \n",
        "#network.save('/content/drive/MyDrive/APT/Models/fasttext_without_all_tokens_with_numbers') \n",
        "#network.save('/content/drive/MyDrive/APT/Models/fasttext_without_numbers_partially') "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ngEk1keOAeNU",
        "outputId": "7bb0971f-677c-4d83-dd3f-7efe1523d014"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /content/drive/MyDrive/APT/Models/word2vec_without_numbers_partially/assets\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_model = tf.keras.models.load_model('/content/drive/MyDrive/APT/Models/fasttext_without_numbers_partially')"
      ],
      "metadata": {
        "id": "AYEWOxTDSdDI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_model.evaluate(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AnsV-yFZUFC2",
        "outputId": "1edde297-c7b4-43a1-95e8-4621805f820e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "64/64 [==============================] - 0s 5ms/step - loss: 0.0220 - mse: 0.0439\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021969186142086983, 0.043938372284173965]"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = new_model.predict(X_test)"
      ],
      "metadata": {
        "id": "xgfGBdfEVRDw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "preds = np.array([i*4 for i in preds])\n",
        "y_test = np.array([i*4 for i in y_test])"
      ],
      "metadata": {
        "id": "nO5KIP46ERMM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(preds[:10])\n",
        "print(y_test[:10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1s6cis25EfHW",
        "outputId": "f485c49c-6bea-42c2-a8fa-58f92e0cb13b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[3.5647788]\n",
            " [2.8660789]\n",
            " [2.9645488]\n",
            " [1.659944 ]\n",
            " [3.7520533]\n",
            " [1.1688416]\n",
            " [3.7652392]\n",
            " [3.9844708]\n",
            " [3.577681 ]\n",
            " [3.915019 ]]\n",
            "[3. 4. 2. 3. 4. 1. 2. 4. 3. 4.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mean_squared_error(y_test,preds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cQxFhVKDEVNL",
        "outputId": "14b49e18-0f8d-447a-b9a6-14a55a1953e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7030138617969074"
            ]
          },
          "metadata": {},
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(np.sum(X_test, axis=1), y_test, color = 'red', label='expected values')\n",
        "plt.scatter(np.sum(X_test, axis=1), new_model.predict(X_test)*4, color = 'blue', label='predicted values')\n",
        "plt.title('Deep neural network')\n",
        "plt.xlabel('X_test')\n",
        "plt.ylabel('y_test')\n",
        "plt.legend(loc=\"best\")\n",
        "plt.savefig('/content/drive/MyDrive/APT/Models/graph_NN.jpg', bbox_inches='tight')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "ZX_QGt_Kp9TG",
        "outputId": "e6a91e47-837c-4f57-c519-924a5f88de10"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "f2bf11d8767c50a74e7ca8cca20ade7bf72bdfe435dc3a1ec7a8fe848b18ee20"
    },
    "kernelspec": {
      "display_name": "Python 3.9.11 ('tarlab1')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.11"
    },
    "orig_nbformat": 4,
    "colab": {
      "name": "model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}